{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python CCD Data Reduction\n",
    "---\n",
    "\n",
    "### Names: [Enter your names here]\n",
    "\n",
    "\n",
    "This notebook walks through the basics of CCD data reduction within python. More detailed instructions (involving more powerful pieces of software) can be found in the CCD Data Reduction Guide written by Matt Craig and Lauren Chambers [https://mwcraig.github.io/ccd-as-book/00-00-Preface](https://mwcraig.github.io/ccd-as-book/00-00-Preface), which itself is based on the [IRAF CCD reduction](http://ircamera.as.arizona.edu/Astr_518/irafguid.pdf) and [stellar photometry](https://www.mn.uio.no/astro/english/services/it/help/visualization/iraf/daophot2.pdf) guides by Phil Massey. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "####  Previous Code\n",
    "This section is a quick recap of the code that you have seen in the previous two labs.\n",
    "\n",
    "*Load in an external package*\n",
    "\n",
    "`import numpy as np`\n",
    "\n",
    "*Define a function with one required input and one optional input (the optional input has a default value)*\n",
    "\n",
    "`\n",
    "def myfunc(variable1, variable2='Something'):\n",
    "    return variable1\n",
    "`\n",
    "\n",
    "*Square root*\n",
    "\n",
    "`np.sqrt(3.5)`\n",
    "\n",
    "*Cosine*\n",
    "\n",
    "`np.cos(1.2)`\n",
    "\n",
    "*Convert from degrees to radians*\n",
    "\n",
    "`np.radians(70)`\n",
    "\n",
    "*Read in data from a file into an array:*\n",
    "\n",
    "*Read in everything as a float*\n",
    "\n",
    "`data = np.loadtxt('myfile.txt')`\n",
    "\n",
    "*Read in everything as a string*\n",
    "\n",
    "`data = np.loadtxt('myfile.txt',dtype=str)`\n",
    "\n",
    "*Read in everything as a string, and skip the first row*\n",
    "\n",
    "`data = np.loadtxt('myfile.txt',dtype=str,skiprows=1)`\n",
    "\n",
    "*Read in everything as a string, skip the first row, and skip rows that start with ':'*\n",
    "\n",
    "`data = np.loadtxt('myfile.txt',dtype=str,skirows=1,comments=':')`\n",
    "\n",
    "*Read in everything as a string, skip the first row, skip rows that start with ':', and the columns are separated by commas*\n",
    "\n",
    "`data = np.loadtxt('myfile.txt',dtype=str,skiprows=1,comments=':',delimiter=',')`\n",
    "\n",
    "\n",
    "*Convert from string to a float*\n",
    "\n",
    "`x = float(mystring)`\n",
    "\n",
    "*For loop:*\n",
    "\n",
    "`\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "`\n",
    "\n",
    "*For loop, over elements in a list*\n",
    "\n",
    "`\n",
    "for element in mylist:\n",
    "    print(element)\n",
    "`\n",
    "\n",
    "*If statement*\n",
    "\n",
    "`\n",
    "if x>5:\n",
    "    print(x)\n",
    "`\n",
    "\n",
    "*Access a certain column/row in a two-dimensional array*\n",
    "\n",
    "`\n",
    "fifth_column = data[:,4]\n",
    "third_row = data[2,:]\n",
    "entry1 = data[1,3] #value from the 2nd row and the fourth column\n",
    "`\n",
    "\n",
    "*Slicing through an array*\n",
    "\n",
    "`slice = myarray[2:5] # selects elements at position 2, 3, and 4 from a one dimensional array`\n",
    "\n",
    "*Create an empty list*\n",
    "\n",
    "`mylist = []`\n",
    "\n",
    "*Append items to a list*\n",
    "\n",
    "`mylist.append(newvalue)`\n",
    "\n",
    "*Return the length of a list*\n",
    "\n",
    "`len(mylist)`\n",
    "\n",
    "*Take the average of a list (assuming they are floats) or an array*\n",
    "\n",
    "`np.mean(mylist)`\n",
    "\n",
    "\n",
    "*Plot data points* \n",
    "\n",
    "`\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x,y,marker='o',color='k',linestyle='')\n",
    "`\n",
    "\n",
    "*Add a label to the X-axis*\n",
    "\n",
    "`plt.xlabel('My X-axis')`\n",
    "\n",
    "*Add a label to the Y-axis*\n",
    "\n",
    "`plt.ylabel('My Y-axis')`\n",
    "\n",
    "*Add a title*\n",
    "\n",
    "`plt.title('My Title)'`\n",
    "\n",
    "*Add a vertical line*\n",
    "\n",
    "`plt.axvline(vertical_value)`\n",
    "\n",
    "*Add a horizontal line*\n",
    "\n",
    "`plt.axhline(horizontal_value)`\n",
    "\n",
    "\n",
    "#### New Code:\n",
    "\n",
    "This lab will introduce a number of different pieces of code, including code that can:\n",
    "\n",
    "- *Open a fits file*\n",
    "- *Get info on the fits file*\n",
    "- *Read the data from a fits file into a variable*\n",
    "- *Read the header from a fits file into a variable*\n",
    "- *Access elements of the header*\n",
    "- *Output the shape of a numpy array*\n",
    "- *Display an image using the show_image function*\n",
    "- *Plot a histogram*\n",
    "- *`plt.xlim(value1,value2)`*\n",
    "- *Close a fits file*\n",
    "- *`np.zeros((dimension1,dimension2))`*\n",
    "- `enumerate(mylist)`\n",
    "- *Take the median along one dimension of a multi-dimensional array*\n",
    "- *Just read in the header*\n",
    "- *Add a new element to the header*\n",
    "- *Create a new fits file*\n",
    "- *Write out a fits file*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing CCD Data\n",
    "\n",
    "Any data taken at an observatory must go through a number of steps before it can be used for scientific analysis. This includes correcting for the bias level, the dark current, and inhomogeneities in the sensitivity across the detector. These contributions can be accounted for with the use of bias frames, dark frames, and flat field images. *Bias frames* are images with an exposure time of zero, and represent the number of counts that each pixel starts with  before any contribution from the sky, or other sources of electrons. *Dark frames* represent the contribution from the thermal electrons; they are matched to the exposure time of the science image since the thermal signal increases with time. *Flat field frames* are images of a uniformly illuminated object. Any differences in the recorded signal between different pixels in a flat field image are most likely due to differences in the response rate of different pixels. \n",
    "\n",
    "Bias and dark frames are subtracted from the science image, while a normalized flat field frame is divided off to produce a processed image. The formula for constructing a useable science image from a raw image is:\n",
    "\n",
    "$science = \\frac{raw - bias - dark}{flat}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the necessary packages\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias Frames (and basic fits handling in python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets read in a bias frame. A subset of the most recent set of calibration data taken at our observatory are located in the Cal_data folder, and we will look at the `CalR-0001Bias.fit` file (The rest of the calibration files are located on the Astro server in Shared/CCD_Data/2020/01_31_20/Calibration). \n",
    "\n",
    "We will use the `astropy` package, which includes the ability to read in fits files. Fits files are read into an HDUList object, which is a flexible data type that contains the data as well the header. [More info about fits files in python can be found on the [astropy.io.fits documentation page.](https://docs.astropy.org/en/stable/io/fits/)] \n",
    "\n",
    "Below, after reading in the fits file into the variable `bias1`, we use the `.info()` function to print information about the fits file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits #<- Need to load the fits package from astropy.io\n",
    "\n",
    "# Read in a bias frame\n",
    "bias1 = fits.open('Cal_data/CalR-0001Bias.fit')\n",
    "bias1.info() #print basic info about the fits file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the `.info()` function says that this fits file has one extension (since there is only one line of output), and has dimensions 1024x1024. The data and header for this extension can be accessed using `.data` and `.header`, as shown below. If other extensions existed, they could be accessed in a similar manner, by simply changing the index. All of the files that you will look at today will only have one extension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_data = bias1[0].data\n",
    "bias_header = bias1[0].header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The header is a dictionary and individual elements, such as the image type and the exposure time, can be accessed as with dictionaries. We can print off all of the keys to see what they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Image Type: {}'.format(bias_header['imagetyp'])) #Image type header keyword\n",
    "print('Exposure Time: {}'.format(bias_header['exptime'])) #Exposure time image keyword\n",
    "print('---')\n",
    "for key in bias_header.keys():\n",
    "    print(key) #Print out the keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data themselves are a numpy array, and the flux in individual pixels can be accessed in the same way as with any two-dimensional array. As we saw based on the result from the `.info()` function the data has dimensions 1024x1024. We can verify these dimensions by looking at the `shape` of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of the array: {}'.format(bias_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it is a regular numpy array, we can access the flux values at various locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Flux in corner element {}'.format(bias_data[0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Q:** Modify the following code to print out the flux in the central pixel, and the average of the flux in the fifth column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Flux in center element {}'.format(x)) # <- replace x with the appropriate code\n",
    "print('Average flux in fifth column {}'.format(np.mean(x))) # <- replace x with the appropriate code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `convenience_functions.py` file contains a function called `show_image` that can help in displaying images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convenience_functions import show_image #<- Load the show_image function\n",
    "show_image(bias_data,cmap='gray') #<- show_image takes as input a 2d numpy array and the colormap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a bias frame, this image represents the state of the detector before it has been exposed to light. Variations in pixel value are partly due to read noise, as well as defects in the detector. We can look at the distribution of pixel values using the `hist` function from matplotlib (which we met in the first lab)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(bias_data.flatten(),10000,histtype='step')\n",
    "plt.xlim(1300,1700) # <-- What does this line do??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Q:** To the above code block, add code to label the X-axis as 'Counts' and add the title 'Distribution of Bias Counts'.\n",
    ">\n",
    "\n",
    "> **Q:** What does the `plt.xlim(1300,1700)` line do? You can either look up the answer on the interwebs, use the help function to look at its docstring, or you can play around with the values to see what changes. \n",
    ">\n",
    "> **A:** **[your answer here]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dark Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets look at a dark frame. \n",
    "\n",
    "> **Q:** As we did with the bias frame, read in the first dark frame (`CalR-0001Dark.fit`) from the `Cal_data` folder and display the image using the `show_image` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in a dark frame, and display the image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dark frame represents the contribution from thermal electrons. The image was taken with the shutter closed and an exposure time of sixty seconds. The pixel values are only slightly higher than the bias frame, suggesting that the dark current is not very high. We can calculate the dark current by subtracting a bias image, and then dividing the result by the exposure time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Q:** The following function calculates the average dark current, in electrons per second, based on a given dark frame. *But there are errors and missing lines in the function.* Correct the errors and missing lines so that the function runs properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dark_current(dark_filename):\n",
    "    dark_image = #Insert code that reads the fits file dark_filename into the variable dark_image\n",
    "    dark_data = dark_image[0].data\n",
    "    dark_header = dark_image[0].header\n",
    "    exp_time = #Insert code that reads the exptime keyword from the header, places this value in the variable exp_time\n",
    "    dark_image.close()\n",
    "    gain = 2.\n",
    "    avg_dark_current = gain*np.mea(dark_data)/exp_time\n",
    "    print('Average Dark current: {:0.2f} e-/sec'.format(avg_current)\n",
    "\n",
    "calc_dark_current(Cal_Data/CalR-0001Dark.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flat Field\n",
    "\n",
    "Now lets look at the flat field\n",
    "\n",
    "> **Q:** As we did with the bias frame, read in the first flat field frame (`CalR-0001R.fit`) from the `Cal_data` folder. Display the image using the `show_image` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in a flat field, and display the image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing science data\n",
    "\n",
    "A science image needs to be corrected for the dark, bias, and flat field. This can be done based on individual dark, bias and flat field images, but it is much better to combine multiple frames. This is because each frame contains read noise on the individual pixels. By averaging multiple frames we can reduce the contributions of this read noise. \n",
    "\n",
    "The following introduces how to combine multiple frames, and how to save the output. First we will set up a dictionary that contains the names of all of the calibration files. This includes the bias frames, the dark frames, and the flat field images for each filter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with the file names of the bias frames, dark frames, and flat field frames\n",
    "data_files = {'biases': ['Cal_data/CalR-0001Bias.fit','Cal_data/CalR-0002Bias.fit','Cal_data/CalR-0003Bias.fit',\n",
    "          'Cal_data/CalR-0004Bias.fit','Cal_data/CalR-0005Bias.fit','Cal_data/CalR-0006Bias.fit',\n",
    "          'Cal_data/CalR-0007Bias.fit','Cal_data/CalR-0008Bias.fit','Cal_data/CalR-0009Bias.fit',\n",
    "          'Cal_data/CalR-0010Bias.fit','Cal_data/CalV-0001Bias.fit','Cal_data/CalV-0002Bias.fit',\n",
    "            'Cal_data/CalV-0003Bias.fit','Cal_data/CalV-0004Bias.fit','Cal_data/CalV-0005Bias.fit',\n",
    "            'Cal_data/CalV-0006Bias.fit','Cal_data/CalV-0007Bias.fit','Cal_data/CalV-0008Bias.fit',\n",
    "            'Cal_data/CalV-0009Bias.fit','Cal_data/CalV-0010Bias.fit'],\n",
    "              'darks':['Cal_data/CalR-0001Dark.fit','Cal_data/CalR-0002Dark.fit','Cal_data/CalR-0003Dark.fit',\n",
    "        'Cal_data/CalR-0004Dark.fit','Cal_data/CalR-0005Dark.fit','Cal_data/CalV-0001Dark.fit',\n",
    "        'Cal_data/CalV-0002Dark.fit','Cal_data/CalV-0003Dark.fit','Cal_data/CalV-0004Dark.fit',\n",
    "        'Cal_data/CalV-0005Dark.fit'],\n",
    "              'Rflats':['Cal_data/CalR-0001R.fit','Cal_data/CalR-0002R.fit','Cal_data/CalR-0003R.fit',\n",
    "        'Cal_data/CalR-0004R.fit','Cal_data/CalR-0005R.fit']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will open each bias frame and save the data into one large master array (`bias_data`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the bias frames\n",
    "bias_data = np.zeros((len(data_files['biases']),1024,1024)) #First create an empty numpy array with the right dimensions\n",
    "for i,file in enumerate(data_files['biases']): #<-- What is this magic here??\n",
    "    image = fits.open(file)\n",
    "    bias_data[i,:,:] = image[0].data\n",
    "    image.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the for loop above, I introduced the `enumerate` function. This function takes in a list and returns two items: the first is an index, and the second is the value of the list at that index. We can see how this works if I run a simple for loop that prints out the two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,file in enumerate(data_files['biases']):\n",
    "    print(i,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it steps through the elements of the list, the `enumerate` function returns the index at each position, and the value of the list at that position. When employed in the for loop, this allows us to use the file name for reading in the fits file, and then use the index when placing the data within our combined array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets return to the `bias_data` variable. This is a three dimensional array, with dimensions (Number of bias frames) x (Number of Rows) x (Number of Columns). As with any numpy array, individual elements can be specified using square brackets, but now three indeces need to be specified. The for loop above puts each image into a different portion of the array, so that all of the data is accessible in one array. \n",
    "\n",
    "> **Q:** Which of the following lines of code selects the center pixel of the 1st image? (Delete the incorrect answers)\n",
    ">\n",
    ">`bias_data[512,512,1]`\n",
    ">\n",
    ">`bias_data[1,512,512]`\n",
    ">\n",
    ">`bias_data[0,512,512]`\n",
    ">\n",
    ">`bias_data[512,512,0]`\n",
    "\n",
    "\n",
    "> **Q:** Which of the following lines of code selects out all of the data from the ninth image? (Delete the incorrect answers)\n",
    ">\n",
    ">`bias_data[8,:,:]`\n",
    ">\n",
    ">`bias_data[8,1:512,1:512]`\n",
    ">\n",
    ">`bias_data[8,1:1024,1:1024]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to combine all of these images into one image. At each pixel position we want to take the median across all of the images. In this way we construct a new image that has the same dimensions as the original images, but has less noise. This could be done using two for loops (one looping over rows and the other looping over columns), but the median function within numpy has this functionality built in. The following line of code will take the median along the 1st axis at each position in the 2nd and 3rd axis (e.g. at each pixel position, take the median across all of the images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_bias = np.median(bias_data,axis=0) #<- The axis keyword starts counting at zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets look at a single bias frame and the combined bias frame side by side. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(bias_data[0,:,:],cmap='gray')\n",
    "plt.title('One Bias Frame')\n",
    "\n",
    "show_image(combined_bias,cmap='gray')\n",
    "plt.title('Combined Bias Frame')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the combined bias frame looks less grainy. That is because the graininess was due to read noise, which is reduced when taking a median combination of multiple frames. \n",
    "\n",
    "Next we will write out the median-combined bias frame so that we can access it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out the combined bias file\n",
    "\n",
    "# First read in the header from one of the bias files, and add a comment to say that this is a combined file\n",
    "hdr = fits.getheader('Cal_data/CalR-0001Bias.fit') #<- just read in the header. This saves time and memory\n",
    "hdr['history'] = 'Median combination bias frame' #<- Add a new keyword, with the given value (just like any other dictionary)\n",
    "\n",
    "# Create a new HDU object \n",
    "hdu = fits.PrimaryHDU(combined_bias,hdr)\n",
    "hdu.writeto('Reduced_data/combined_bias.fits',overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to do the same thing for the dark and flat field frames. The procedure is very similar, with two additional considerations:\n",
    "- We must subtract the bias level from each dark frame before they are median-combined. We want to final combined dark image to only represent the dark current, not the dark current plus the bias level.\n",
    "- Each flat image must have the bias level subtracted, as well as the dark current. After creating a combined flat field image, we then need to normalize this combined image, which we can do by dividing the image by its median value. \n",
    "\n",
    "Lets start with the dark frame. \n",
    "\n",
    "> **Q:** The code below gives the basic outline for creating a median-combined, bias subtracted, dark frame. Insert the necessary lines of code to complete this code block. (There are no intentional errors in this code block, just missing pieces of code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets do the same for the dark frame, making sure to subtract off the bias\n",
    "\n",
    "# Read in the dark frames\n",
    "dark_data = np.zeros((len(data_files['darks']),1024,1024))\n",
    "for i,file in enumerate(data_files['darks']):\n",
    "    image = fits.open(file)\n",
    "    dark_data[i,:,:] = #Insert code to input the dark image data, while subtracting off the bias\n",
    "    image.close() \n",
    "    \n",
    "#Insert code to median combine the dark_data array\n",
    "combined_dark = \n",
    "\n",
    "\n",
    "# Write out the combined dark file\n",
    "# First read in the header from one of the dark files, and add a comment to say that this is a combined file\n",
    "hdr = fits.getheader('Cal_data/CalR-0001Dark.fit')\n",
    "hdr['history'] = 'Median combination dark frame'\n",
    "\n",
    "# Create an HDU object from the data and header, and write out the result. \n",
    "hdu = fits.PrimaryHDU(combined_dark,hdr)\n",
    "hdu.writeto('Reduced_data/combined_dark.fits',overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(dark_data[0,:,:],cmap='gray')\n",
    "plt.title('One Dark Frame')\n",
    "\n",
    "show_image(combined_dark,cmap='gray')\n",
    "plt.title('Combined Dark')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Q:** Now repeat for the flat field images. Make sure to subtract off both the bias level and the dark current. The dark current must be scaled to the exposure time of the flat field images. To do this, divide the combined dark current image by the exposure time of the dark current image (60 seconds) to get the dark current per second, and then multiply by the exposure time of the flat field image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "flat_data = np.zeros((len(data_files['Rflats']),1024,1024))\n",
    "for i,file in enumerate(data_files['Rflats']):\n",
    "    image = fits.open(file)\n",
    "    header = image[0].header\n",
    "    exptime = # Insert code to read in the exposure time from the header\n",
    "    flat_data[i,:,:] = #Insert code to read the data from image, and subtract both the bias and the scaled dark\n",
    "    image.close()\n",
    "    \n",
    "# Insert code to median combine the flat data, and place the results into a variable called combined_flat\n",
    "combined_flat = \n",
    "# Next, normalize the flat field image. \n",
    "#   Both of the following statements are equivalent (we keep one commented out because we don't want to divide twice)\n",
    "combined_flat = combined_flat/np.median(combined_flat)\n",
    "#combined_flat /= np.median(combined_flat)\n",
    "\n",
    "\n",
    "# First read in the header from one of the flat files, and add a comment to say that this is a combined file\n",
    "hdr = fits.getheader('Cal_data/CalR-0001R.fit')\n",
    "hdr['history'] = 'Median combination flat frame'\n",
    "\n",
    "# Insert code to create a new HDU object, using combined_flat and hdr. \n",
    "\n",
    "# Save the result in the Reduced_data directory, as combined_Rflat.fits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(flat_data[0,:,:],cmap='gray')\n",
    "plt.title('One Flat Frame')\n",
    "\n",
    "show_image(combined_flat,cmap='gray')\n",
    "plt.title('Combined Flat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our master bias, dark, and flat field images, we can apply them to a science image.\n",
    "\n",
    "> **Q:** Below is the beginning of a function that will read in a science image, and then perform the bias/dark/flat corrections. It takes as inputs the filename of the raw image (as a string), the filename of the output file (a string, and it should be different from the original filename), and the name of the bias, dark, and flat field frames. Building on what you have done earlier, complete this function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(filename,new_filename,bias_file='Reduced_data/combined_bias.fits',dark_file = 'Reduced_data/combined_dark.fits',\n",
    "                flat_file = 'Reduced_data/combined_flat.fits'):\n",
    "    \n",
    "    image = #Insert code to read in the raw science fits file.\n",
    "    data = #insert code to extract the data from image\n",
    "    hdr = #Insert code to read in the header from the science file\n",
    "    exptime = #Insert code to read in the exposure time\n",
    "    #Insert code to close the science file\n",
    "    \n",
    "    bias_image = #Insert code to read in bias fits file\n",
    "    bias_data = #Insert code to read in bias data from bias_image\n",
    "    #Insert code to close the bias file\n",
    "    \n",
    "    dark_image = #Insert code to read in the dark fits file\n",
    "    dark_data = #Insert code to read in the dark data from dark_image\n",
    "    #Insert code to close the dark fits file\n",
    "    \n",
    "    flat_image = #Insert code to read in the flat field image\n",
    "    flat_data = #Insert code to read in the flat data from flat_image\n",
    "    #Insert code to close the flat field image\n",
    "    \n",
    "    proc_data = #Insert code to apply the calibration steps to the data\n",
    "    \n",
    "    #Insert code to write out the processed data. \n",
    "    #Use the header from the original image, but add a keyword that says it has been processed.\n",
    "    hdu.writeto(new_filename,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test your code using this code block\n",
    "process_data('M101_MartiC_180-0001.fit','M101_MartiC_180-0001_proc.fits')\n",
    "\n",
    "old_image = fits.open('M101_MartiC_180-0001.fit')\n",
    "old_data = old_image[0].data\n",
    "old_image.close()\n",
    "\n",
    "new_image = fits.open('M101_MartiC_180-0001_proc.fits')\n",
    "new_data = new_image[0].data\n",
    "new_image.close()\n",
    "\n",
    "show_image(old_data,cmap='gray')\n",
    "plt.title('Raw Image')\n",
    "\n",
    "show_image(new_data,cmap='gray')\n",
    "plt.title('Processed Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the list of new code from the beginning of the lab. Fill in each line with the new code, or a description of what the code does.\n",
    "\n",
    "#### New Code:\n",
    "- *Open a fits file*: \n",
    "- *Get info on the fits file*: \n",
    "- *Read the data from a fits file into a variable*: \n",
    "- *Read the header from a fits file into a variable*:\n",
    "- *Access elements of the header*: \n",
    "- *Output the shape of a numpy array*\n",
    "- *Display an image using the show_image function*: \n",
    "- *Plot a histogram*: \n",
    "- *`plt.xlim(value1,value2)`*: \n",
    "- *Close a fits file*: \n",
    "- *`np.zeros((dimension1,dimension2,dimension3))`*:\n",
    "- `enumerate`: \n",
    "- *Take the median along one dimension of a multi-dimensional array*: \n",
    "- *Just read in the header*: \n",
    "- *Add a new element to the header*: \n",
    "- *Create a new fits file*: \n",
    "- *Write out a fits file*: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stop Here** \n",
    "\n",
    "Save your ipython notebook, add the names of your group members to the filename, and copy the notebook back to the server in Astro211_S20/Place_Your_Results_Here/Lab4_CCD/\n",
    "\n",
    "You do not need to copy any of the fits files that you created, just the jupyter notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
